{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan, linewidth=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_hierarchy(filename):\n",
    "    \"\"\"\n",
    "    Parses a hierarchy file of concepts. Subsumption is denoted by \\t.\n",
    "    A tree-shaped hierarchy should be avoided, as tree is too nice in some properties.\n",
    "    Currently the hierarchy is a forest with overlapping leaf nodes, making it maximally sparse by default.\n",
    "    Returns:\n",
    "        id_name: list of concepts as dict<id, concept>\n",
    "        name_id: dict<concept, id>\n",
    "        g: hierarchy graph as an adjacency matrix\n",
    "    \"\"\"\n",
    "    with open(filename, mode='r') as h:\n",
    "        lines = h.read().splitlines()\n",
    "    id_name = list(set(x.strip() for x in lines if x))\n",
    "    n = len(id_name)  # number of concepts\n",
    "    name_id = dict(zip(id_name, range(0, n)))\n",
    "    g = np.zeros((n, n), dtype=np.bool)\n",
    "    stack = list()\n",
    "    for x in lines:\n",
    "        depth = x.count('\\t', 0, len(x) - len(x.lstrip()))\n",
    "        name = x.strip()\n",
    "        if depth < len(stack) - 1:  # arbitrary levels shallower\n",
    "            del stack[depth:]  # pop until len(stack)==depth\n",
    "        if depth == 0 and len(stack) == 0:  # root node\n",
    "            stack.append(name)\n",
    "        elif depth == len(stack):  # one level deeper\n",
    "            from_id = name_id[stack[-1]]\n",
    "            to_id = name_id[name]\n",
    "            g[from_id, to_id] = True\n",
    "            stack.append(name)\n",
    "        elif depth == len(stack) - 1:  # same level\n",
    "            from_id = name_id[stack[-2]]\n",
    "            to_id = name_id[name]\n",
    "            g[from_id, to_id] = True\n",
    "            stack[-1] = name\n",
    "        else:  # arbitrary levels shallower, but haven't reached root\n",
    "            from_id = name_id[stack[-1]]\n",
    "            to_id = name_id[name]\n",
    "            g[from_id, to_id] = True\n",
    "            stack.append(name)\n",
    "    return id_name, name_id, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_name, name_id, H = read_hierarchy('hierarchy_full.txt')  # H for hierarchy (directed) subgraph\n",
    "n = len(id_name)  # number of nodes. Currently 32, including 12 branch nodes and 20 leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# debug functions\n",
    "def print_bool_matrix(m):  # np.set_printoptions(threshold=np.nan, linewidth=np.nan)\n",
    "    print(np.array_str(m.astype(np.uint8)))\n",
    "def print_edges(g):  # defined outside: id_name\n",
    "    edges = set()\n",
    "    for x, y in np.argwhere(g):\n",
    "        if g[y, x]:\n",
    "            key1 = '{} <-> {}'.format(id_name[x], id_name[y])\n",
    "            key2 = '{} <-> {}'.format(id_name[y], id_name[x])\n",
    "            if key1 not in g and key2 not in g:\n",
    "                edges.add(key1)\n",
    "        else:\n",
    "            edges.add('{} -> {}'.format(id_name[x], id_name[y]))\n",
    "    print('\\n'.join(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import floyd_warshall\n",
    "H_ts = floyd_warshall(H, unweighted=True) != np.inf  # H_ts for transitive closure of H with self-loops\n",
    "H_t = H_ts - np.eye(n, dtype=np.bool)  # H_t for transitive closure of H without self-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_exclusion(H_ts):\n",
    "    \"\"\"\n",
    "    Builds exclusion subgraph from hierarchy. Two nodes are exclusive unless they share a common descendant.\n",
    "    Args:\n",
    "        H_ts: Transitive closure of hierarchical subgraph with self-loop. Self-loop is mandatory as the common descendant of two nodes may be one of them.\n",
    "    \"\"\"\n",
    "    n = H_ts.shape[0]\n",
    "    g = np.ones((n, n), dtype=np.bool) - np.eye(n, dtype=np.bool)  # fully connected by default\n",
    "    for i in range(0, n):\n",
    "        for j in range(i + 1, n):\n",
    "            if np.logical_and(H_ts[i], H_ts[j]).any():  # if two nodes share a descendant, then unconnect\n",
    "                g[i, j] = g[j, i] = False\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EX = build_exclusion(H_ts)  # EX for exclusion (undirected) subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dfs_connected(g, from_id, to_id):\n",
    "    def dfs(at_id):  # defined outside: visited\n",
    "        if at_id == to_id:\n",
    "            return True\n",
    "        visited[at_id] = True\n",
    "        for x in np.nonzero(g[at_id])[0]:  # nodes that can be visited from @at_id\n",
    "            if not visited[x] and dfs(x):\n",
    "                return True\n",
    "        return False\n",
    "    visited = np.zeros(n, dtype=np.bool)\n",
    "    return dfs(from_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparsify(g, edges):\n",
    "    \"\"\"\n",
    "    For each undirected edge (x, y), if both directions are still connected without (x, y), then (x, y) is removed.\n",
    "    This algorithm does not guarantee maximal sparsity. See counter-example on Deng et al, page 8.\n",
    "    Approximating |E| by |V|^2, this brute-force solution has complexity O(|V|^3).\n",
    "    Args:\n",
    "        edges: iterable<tuple<int, int>>\n",
    "    \"\"\"\n",
    "    for x, y in edges:\n",
    "        m = np.copy(g)\n",
    "        m[x, y] = m[y, x] = False\n",
    "        if dfs_connected(m, x, y) and dfs_connected(m, y, x):\n",
    "            g[x, y] = g[y, x] = False\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEX_sparse = sparsify(H + EX, np.argwhere(EX))  # recall that @H is already maximally sparse\n",
    "HEX_dense = H_t + EX - np.eye(n, n, dtype=np.bool)  # recall that @EX is already maximally dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_state_space(H_t, EX):\n",
    "    \"\"\"\n",
    "    Lists the state space of a HEX graph. Algorithm based on Deng et al, page 9\n",
    "    1. Find a node without in-edges in the hierarchy subgraph as the seed.\n",
    "    2. In a recursive divide-and-conquer manner, assign the pivot as true/false.\n",
    "    3. In each recursive step:\n",
    "        3.1. find a node in the partially assigned state that has not been assigned a value,\n",
    "            but all its ancestors have. If all its ancestors are True, then this node is True-able.\n",
    "        3.2. Assigning True to a node means all nodes exclusive to it are false.\n",
    "        3.3. Assigning False to a node means all its offsprings are false.\n",
    "    \"\"\"\n",
    "    def find_pivot(pas):  # find a node whose ancestors have all been assigned a value, but itself hasn't\n",
    "        for i in np.where(pas == 0)[0]:\n",
    "            ancestors = np.where(H_t[:, i])[0]\n",
    "            if np.all(pas[ancestors]):\n",
    "                true_able = np.all(pas[ancestors] == 1) or ancestors.size == 0\n",
    "                return i, true_able  # the pivot can be true only if all its ancestors are true\n",
    "\n",
    "    def bss_step(pas):  # pas for partially assigned state\n",
    "        if np.count_nonzero(pas) == n:  # if all variables have been assigned a value\n",
    "            return {tuple(pas)}\n",
    "        p, true_able = find_pivot(pas)\n",
    "        p_false = pas.copy()\n",
    "        p_false[p] = -1  # pivot is false. Nodes exclusive to the pivot are free\n",
    "        p_false[np.where(H_t[p][0])] = -1  # all offsprings of the pivot are false\n",
    "        if true_able:\n",
    "            p_true = pas.copy()\n",
    "            p_true[p] = 1  # pivot is true. Immediate children of the pivot are free\n",
    "            p_true[np.where(EX[p])[0]] = -1  # nodes exclusive to the pivot are false\n",
    "            return bss_step(p_true).union(bss_step(p_false))\n",
    "        return bss_step(p_false)\n",
    "\n",
    "    s = np.where(H_t.sum(axis=0) == 0)[0][0]  # pick any node without in-edges in @H_t as the seed\n",
    "    s_true = np.zeros(n, dtype=np.int8)  # 0 for free variable, 1 for true, -1 for false\n",
    "    s_true[s] = 1\n",
    "    s_false = np.zeros(n, dtype=np.int8)\n",
    "    # must not write 'seed_true = seed_false = ...', as the two variables would point to the same object\n",
    "    s_false[s] = -1\n",
    "    return np.array(list(bss_step(s_true).union(bss_step(s_false)))) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# debug function\n",
    "def print_state_space(state_space):\n",
    "    print('size=' + str(len(state_space)))\n",
    "    for x in state_space:\n",
    "        print([id_name[i] for i in range(0, len(x)) if x[i] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_space = build_state_space(H_t, EX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_hierarchical_labels(H_ts, state_space):\n",
    "    \"\"\"\n",
    "    For each node, finds in the state space, all legal states of its ancestors, except for the all-False trivial state.\n",
    "    For each such states, the set of active (True) ancestors of that node forms one of its hierarchical labels.\n",
    "    Returns:\n",
    "        id_hierarchical_labels: list<list<tuple<id>>>, used as dict<id, list<tuple<id>>>\n",
    "    \"\"\"\n",
    "    id_hierarchical_labels = list()\n",
    "    for i in range(0, n):\n",
    "        active_ances = list()  # list<tuple<id>>\n",
    "        ances_id = np.nonzero(H_ts[:, i])[0]\n",
    "        for s in set(map(tuple, state_space[:, ances_id])):  # for each unique state of ancestors\n",
    "            aas = filter(lambda x: x[1], zip(ances_id, s))  # retains active ancestors. aas for active ancestor state\n",
    "            if aas:  # if ancestors are not all inactive (trivial state)\n",
    "                active_ances.append(zip(*aas)[0])  # id of active ancestors\n",
    "        id_hierarchical_labels.append(active_ances)\n",
    "    return id_hierarchical_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_hls = build_hierarchical_labels(H_ts, state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = {'id_name': id_name, 'name_id': name_id, 'H': H, 'H_t': H_t, 'HEX_sparse': HEX_sparse,\n",
    "        'HEX_dense': HEX_dense, 'state_space': state_space, 'id_hierarchical_labels': id_hls}\n",
    "with open('hex.pickle', mode='wb') as h:\n",
    "    pickle.dump(data, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "def visualize(m, directed):\n",
    "    g = nx.DiGraph() if directed else nx.Graph()\n",
    "    g.add_nodes_from(id_name)\n",
    "    xs, ys = np.nonzero(m)\n",
    "    xs = map(lambda x: id_name[x], xs)\n",
    "    ys = map(lambda x: id_name[x], ys)\n",
    "    g.add_edges_from(zip(xs, ys))\n",
    "    # nx.write_dot(g, 'test.dot')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw(g, pos=nx.spring_layout(g), node_color='white', node_size=2000, with_labels=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize(HEX_sparse, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
