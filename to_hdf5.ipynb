{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('df.pickle', mode='rb') as h:\n",
    "    df_train, df_test = pickle.load(h)\n",
    "with open('hex.pickle', mode='rb') as h:\n",
    "    D = len(pickle.load(h)['id_name'])  # number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "img_dir = '../pascal12/JPEGImages'\n",
    "img_mean = np.load('../ilsvrc_2012_mean.npy').astype(np.float32)  # 3*256*256\n",
    "img_mean = np.swapaxes(np.swapaxes(img_mean, 0, 1), 1, 2)  # convert to XY[BGR]\n",
    "def load_image(filename):\n",
    "    \"\"\"\n",
    "    Loads image, subtract mean, resize to 227*227. No axis rotation or normalization.\n",
    "    Returns:\n",
    "        Result image as an np.float32 array with size 227*227*3. Values within [0, 255].\n",
    "    \"\"\"\n",
    "    img = cv2.resize(cv2.imread(join(img_dir, filename)), (256, 256))\n",
    "    return cv2.resize(img.astype(np.float32) - img_mean, (227, 227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "def save_XY(filename, X, Y=None):\n",
    "    with h5py.File('../{}.h5'.format(filename), mode='w') as h:\n",
    "        h.create_dataset('data', data=X)\n",
    "        if Y is not None:\n",
    "            h.create_dataset('label', data=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = map(load_image, df_train['img'])\n",
    "X_train = np.swapaxes(np.swapaxes(X_train, 2, 3), 1, 2)  # convert to [BGR]XY for caffe classifier. Other classifiers needs to convert back\n",
    "N = len(X_train)  # size of training data\n",
    "Y_train = np.zeros((N, D), dtype=np.float32)\n",
    "pseudo_labels = df_train['pseudo_label']\n",
    "for i in range(0, N):\n",
    "    Y_train[i, pseudo_labels[i]] = 1.0 / len(pseudo_labels[i])  # for softmax + cross entropy loss\n",
    "save_XY('train', X_train, Y_train)\n",
    "save_XY('test', map(load_image, df_test['img']))  # axis order XY[BGR]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
